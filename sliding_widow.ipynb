{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sliding Window Attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.8229,  0.8025, -0.5787, -0.3725,  0.2452],\n",
       "         [ 0.0366, -0.3871,  1.5102,  0.9443, -0.1497],\n",
       "         [-0.6076, -0.5786, -0.4912,  2.0292, -0.0453],\n",
       "         [-0.3350,  0.6715, -0.6786, -0.2576, -0.3165],\n",
       "         [ 0.6325, -0.1481,  0.4003,  1.5457,  0.2917]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(1, 5, 5)\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def causal_mask(size):\n",
    "    mask = torch.triu(torch.ones((1, size, size)), diagonal=1).type(torch.int)\n",
    "    return mask == 0\n",
    "\n",
    "def sliding_mask(size):\n",
    "    mask = torch.triu(torch.ones((1, size, size)), diagonal=-2).type(torch.int)\n",
    "    return mask == 1\n",
    "\n",
    "#for a sliding window of size 3, diagonal = -2, size 4 diagonal -3 etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "causal_mask(8).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [0, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [0, 0, 1, 1, 1, 1, 1, 1],\n",
       "         [0, 0, 0, 1, 1, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 1, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 1, 1, 1]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sliding_mask(8).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 1, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 1, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 1, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 1, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1, 1, 1]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(causal_mask(8) & sliding_mask(8)).int()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RMSNormalization(nn.Module):\n",
    "\n",
    "    def __init__(self, eps:float=10**-8) -> None:\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.alpha = nn.Parameter(torch.ones(1)) # alpha is a learnable parameter\n",
    "        # self.bias = nn.Parameter(torch.zeros(1)) # bias is a learnable parameter\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # x: (batch, seq_len, hidden_size)\n",
    "         # Keep the dimension for broadcasting\n",
    "        squared_x = torch.square(x) \n",
    "        mean = squared_x.mean(dim = -1, keepdim = True) # (batch, seq_len, 1)\n",
    "        \n",
    "        # Keep the dimension for broadcasting\n",
    "        sqrt_mean = torch.sqrt(mean) # (batch, seq_len, 1) \n",
    "\n",
    "\n",
    "        # eps is to prevent dividing by zero or when sqrt_mean is very small\n",
    "        return self.alpha * (x ) / (sqrt_mean + self.eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotatery Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# formula for theta is 10000 ^ -2(i-1)/d\n",
    "# i [ real numbers from 1 to d/2]\n",
    "# we can write it as 1/10000 ^ 2([0 - 256]/d)\n",
    "\n",
    "class RotateryEmbedding(nn.Module):\n",
    "\n",
    "    def __init__(self,seq_len:int,  constant = 10000.0 ,embedding_dim:int=512) -> None:\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.theta = theta\n",
    "        self.aimport torch\n",
    "\n",
    "# Assuming you have two tensors (replace these with your actual data)\n",
    "matrix1 = torch.tensor([1, 2, 3])\n",
    "matrix2 = torch.tensor([4, 5, 6])\n",
    "\n",
    "\n",
    "torch.outer(matrix1, matrix2)lpha = nn.Parameter(torch.ones(1)) # alpha is a learnable parameter\n",
    "        # self.bias = nn.Parameter(torch.zeros(1)) # bias is a learnable parameter\n",
    "\n",
    "    def pre_compute_theta(self, x):\n",
    "\n",
    "\n",
    "        i = torch.arange(0, 256).float()\n",
    "\n",
    "        theta = 1.0 /(constant **((2 * i)/ embedding_dim) )\n",
    "\n",
    "        m = torch.arange(seq_len)\n",
    "\n",
    "        freq = torch.outer(m, theta).float()\n",
    "\n",
    "        # reps the freq in complex form cos(m*theta) + i sin(m*theta)\n",
    "\n",
    "        freqs_complex_form = torch.polar(torch.ones_like(freq), freq)\n",
    "\n",
    "        return freqs_complex_form\n",
    "    def apply_rotary_pos_encoding( x: torch.Tensor, freqs_complex_form: torch.Tensor):  \n",
    "        x_complex = torch.view_as_complex(x.float().reshape(*x.shape[:-1], -1))\n",
    "\n",
    "        freqs_complex_form = freqs_complex_form.unsqueeze(0).unsqueeze(2) \n",
    "\n",
    "        x_rotated = x_complex * freqs_complex_form\n",
    "\n",
    "        x_out = torch.view_as_real(x_rotated) \n",
    "\n",
    "        return x_out.reshape(*x.shape).type_as(x).to(device)\n",
    "        # # x: (batch, seq_len, hidden_size)\n",
    "        #  # Keep the dimension for broadcasting\n",
    "        # squared_x = torch.square(x) \n",
    "        # mean = squared_x.mean(dim = -1, keepdim = True) # (batch, seq_len, 1)\n",
    "        \n",
    "        # # Keep the dimension for broadcasting\n",
    "        # sqrt_mean = torch.sqrt(mean) # (batch, seq_len, 1) \n",
    "\n",
    "\n",
    "        # # eps is to prevent dividing by zero or when sqrt_mean is very small\n",
    "        # return self.alpha * (x ) / (sqrt_mean + self.eps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KV_ CACHE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model:int, heads: int) -> None:\n",
    "        super(MultiHeadAttention,self).__init__()\n",
    "        self.head = heads\n",
    "        self.head_dim = d_model // heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "\n",
    "\n",
    "        assert d_model % heads == 0, 'cannot divide d_model by heads'\n",
    "\n",
    "        ## initialize the query, key and value weights 512*512\n",
    "        self.query_weight = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.key_weight = nn.Linear(d_model, d_model,bias=False)\n",
    "        self.value_weight = nn.Linear(d_model, d_model,bias=False)\n",
    "        self.final_weight  = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "\n",
    "        ## initialize the query, key and value matrices to give us batch, seq_len by 512\n",
    "        self.key_cache = torch.empty(1,0,d_model)\n",
    "        self.value_cache = torch.empty(1,0,d_model)\n",
    "\n",
    "      \n",
    "    def self_attention(self,query, key, value, mask,dropout):\n",
    "\n",
    "        print(f\"key cache {self.key_cache.shape}\")\n",
    "        print(f\"value cache {self.value_cache.shape}\")\n",
    "\n",
    "        # rolling buffer ???? \n",
    "        if self.key_cache.shape == torch.Size([1,4,self.d_model]):\n",
    "            print(f'actual_matrix {self.key_cache}')\n",
    "            self.key_cache = torch.cat((self.key_cache[:, 1:,:], key), dim=1)\n",
    "            self.value_cache = torch.cat((self.value_cache[:, 1:,:], value), dim=1)\n",
    "\n",
    "            print(f'actual_matrix_after {self.key_cache}')\n",
    "        else:    \n",
    "   \n",
    "            self.key_cache = torch.cat((self.key_cache, key), dim=1)\n",
    "            self.value_cache = torch.cat((self.value_cache, value), dim=1)\n",
    "\n",
    "\n",
    "\n",
    "             #splitting query, key and value into heads\n",
    "                #this gives us a dimension of batch, num_heads, seq_len by 64. basically 1 sentence is converted to have 8 parts (heads)\n",
    "        print(f\"key cache_ {self.key_cache.shape}\")\n",
    "        print(f\"value cache_ {self.value_cache.shape}\")        \n",
    "        query = query.view(query.shape[0], query.shape[1],self.head,self.head_dim).transpose(2,1)\n",
    "        key = self.key_cache.view(self.key_cache.shape[0], self.key_cache.shape[1],self.head,self.head_dim).transpose(2,1)\n",
    "        value = self.value_cache.view(self.value_cache.shape[0], self.value_cache.shape[1],self.head,self.head_dim).transpose(2,1)\n",
    "        \n",
    "        attention = query @ key.transpose(3,2)\n",
    "        attention = attention / math.sqrt(query.shape[-1])\n",
    "\n",
    "        if mask is not None:\n",
    "           attention = attention.masked_fill(mask == 0, -1e9)      \n",
    "        attention = torch.softmax(attention, dim=-1)      \n",
    "        if dropout is not None:\n",
    "            attention = dropout(attention)\n",
    "        attention_scores =  attention @ value    \n",
    "       \n",
    "        return attention_scores.transpose(2,1).contiguous().view(attention_scores.shape[0], -1, self.head_dim * self.head)\n",
    "      \n",
    "    def forward(self,query, key, value,mask):\n",
    "\n",
    "        ## initialize the query, key and value matrices to give us seq_len by 512\n",
    "        query = self.query_weight(query)\n",
    "        key = self.key_weight(key)\n",
    "        value = self.value_weight(value)\n",
    "\n",
    "        attention = MultiHeadAttention.self_attention(self, query, key, value, mask, self.dropout)\n",
    "        return self.final_weight(attention) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "mult = MultiHeadAttention(6,2)\n",
    "# MultiHeadAttention(4, 2)(torch.randn(1,1,4), torch.randn(1,1,4), torch.randn(1,1,4), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key cache torch.Size([1, 4, 6])\n",
      "value cache torch.Size([1, 4, 6])\n",
      "actual_matrix tensor([[[-0.3789,  0.0984, -0.5503,  0.0935, -0.9363,  0.3123],\n",
      "         [ 0.0748, -0.0306,  0.1323, -1.4742, -0.0179,  1.7810],\n",
      "         [-0.6320,  0.7551,  0.0666, -0.4027, -1.3768,  0.4777],\n",
      "         [ 0.4627,  0.4404,  0.2701,  0.1492, -0.3385,  0.5148]]],\n",
      "       grad_fn=<CatBackward0>)\n",
      "actual_matrix_after tensor([[[ 0.0748, -0.0306,  0.1323, -1.4742, -0.0179,  1.7810],\n",
      "         [-0.6320,  0.7551,  0.0666, -0.4027, -1.3768,  0.4777],\n",
      "         [ 0.4627,  0.4404,  0.2701,  0.1492, -0.3385,  0.5148],\n",
      "         [-0.6304,  0.0575, -0.3107, -0.2914, -0.5584,  0.1118]]],\n",
      "       grad_fn=<CatBackward0>)\n",
      "key cache_ torch.Size([1, 4, 6])\n",
      "value cache_ torch.Size([1, 4, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0941, -0.0206,  0.0677, -0.0313, -0.0363,  0.1189]]],\n",
       "       grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mult(torch.randn(1,1,6), torch.randn(1,1,6), torch.randn(1,1,6), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.3062,  0.5340,  0.6917],\n",
       "          [ 0.5460, -0.1276,  0.1350]]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(1,1,2,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.3062,  0.5340,  0.6917]],\n",
       "\n",
       "         [[ 0.5460, -0.1276,  0.1350]]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.transpose(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 1])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.cat((x,torch.randn(1,1,1)), dim=1)\n",
    "x.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
